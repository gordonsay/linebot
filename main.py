import os, re, json, openai, random, time, requests
from flask import Flask, request, jsonify
from linebot.exceptions import InvalidSignatureError
from linebot.v3.messaging import MessagingApi, Configuration, ApiClient
from linebot.v3.webhooks import MessageEvent, PostbackEvent, FollowEvent
from linebot.v3.messaging.models import ReplyMessageRequest, TextMessage, FlexMessage, FlexContainer, ImageMessage, PushMessageRequest
from linebot.v3.webhooks.models import TextMessageContent
from linebot.v3.webhooks.models import AudioMessageContent
from linebot.v3.webhook import WebhookHandler
from groq import Groq
from dotenv import load_dotenv
from flask import send_from_directory
from types import SimpleNamespace

# Load Environment Arguments
load_dotenv()

# Grab API Key from .env
GROQ_API_KEY = os.getenv("GROQ_API_KEY")
LINE_CHANNEL_ACCESS_TOKEN = os.getenv("LINE_CHANNEL_ACCESS_TOKEN")
LINE_CHANNEL_SECRET = os.getenv("LINE_CHANNEL_SECRET")
TOGETHER_API_KEY = os.getenv("TOGETHER_API_KEY")
STABILITY_API_KEY = os.getenv("STABILITY_API_KEY")
HUGGING_TOKENS = os.getenv("HUGGING_TOKENS")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
GOOGLE_SEARCH_KEY = os.getenv("GOOGLE_SEARCH_KEY")
GOOGLE_CX = os.getenv("GOOGLE_CX")
BASE_URL = "https://render-linebot-masp.onrender.com"


# Grab Allowed Users and Group ID from .env
allowed_users_str = os.getenv("ALLOWED_USERS", "")
ALLOWED_USERS = {uid.strip() for uid in allowed_users_str.split(",") if uid.strip()}
allowed_groups_str = os.getenv("ALLOWED_GROUPS", "")
ALLOWED_GROUPS = {gid.strip() for gid in allowed_groups_str.split(",") if gid.strip()}

# Initailize LINE API (v3)
config = Configuration(access_token=LINE_CHANNEL_ACCESS_TOKEN)
messaging_api = MessagingApi(ApiClient(config))
handler = WebhookHandler(LINE_CHANNEL_SECRET)
client = Groq(api_key=GROQ_API_KEY)

# Initialize Flask 
app = Flask(__name__)

# Record AI model choosen by User
user_ai_choice = {}

# Global dictionary for translation
user_translation_config = {}    

@app.route("/", methods=["GET"])
def home():
    return "ç‹—è›‹ å•Ÿå‹•ï¼"

@app.route('/static/<path:filename>')
def serve_static(filename):
    return send_from_directory("static", filename)

@app.route("/callback", methods=["POST"])
def callback():
    signature = request.headers.get("X-Line-Signature", "æœªæ”¶åˆ°ç°½å")
    body = request.get_data(as_text=True)

    # ğŸ” Log Webhook Data
    print(f"ğŸ“¢ [DEBUG] Webhook Received: {body}")

    try:
        handler.handle(body, signature)
    except InvalidSignatureError:
        print("âŒ [ERROR] Webhook Signature é©—è­‰å¤±æ•—")
        return "Invalid signature", 400
    except Exception as e:
        print(f"âŒ [ERROR] Webhook è™•ç†éŒ¯èª¤: {e}")

    return "OK", 200

@handler.add(FollowEvent)
def handle_follow(event):
    """ç•¶ç”¨æˆ¶åŠ å¥½å‹æ™‚ï¼Œç«‹å³ç™¼é€é¸å–®"""
    command_list = (
            "ğŸ“ æ”¯æ´çš„æŒ‡ä»¤ï¼š\n"
            "1. æ›æ¨¡å‹: æ›´æ› AI èªè¨€æ¨¡å‹ \n\t\tï¼ˆé è¨­ç‚º Deepseek-R1ï¼‰\n"
            "2. çµ¦æˆ‘id: é¡¯ç¤º LINE å€‹äºº ID\n"
            "3. ç¾¤çµ„id: é¡¯ç¤º LINE ç¾¤çµ„ ID\n"
            "4. ç‹—è›‹å‡ºå»: æ©Ÿå™¨äººé›¢é–‹ç¾¤çµ„\n"
            "5. ç•¶å‰æ¨¡å‹: æ©Ÿå™¨äººç¾æ­£ä½¿ç”¨çš„æ¨¡å‹\n"
            "6. ç‹—è›‹ç”Ÿæˆ: ç”Ÿæˆåœ–ç‰‡\n"
            "7. æˆ‘è¦ç¿»è­¯: ç¿»è­¯èªè¨€\n"
            "8. åœæ­¢ç¿»è­¯: åœæ­¢ç¿»è­¯\n"
            "9. ç‹—è›‹æƒ…å‹’ ç‹—è›‹çš„è¶…èƒ½åŠ›"
        )
    reply_request = ReplyMessageRequest(
        replyToken=event.reply_token,
        messages=[TextMessage(text=command_list)]
    )
    send_response(event, reply_request)

# ----------------------------------
# Support Function
# ----------------------------------
def safe_api_call(api_func, request_obj, retries=3, backoff_factor=1.0):
    """
    å‘¼å« LINE APIï¼Œè‹¥é‡åˆ° 429 éŒ¯èª¤å‰‡æ¡å–æŒ‡æ•¸é€€é¿é‡è©¦æ©Ÿåˆ¶
    """
    for i in range(retries):
        try:
            return api_func(request_obj)
        except Exception as e:
            if "429" in str(e):
                wait_time = backoff_factor * (2 ** i)
                print(f"Rate limit encountered. Retrying in {wait_time} seconds...")
                time.sleep(wait_time)
            else:
                print(f"API call error: {e}")
                raise
    raise Exception("API call failed after retries")

def send_limit_message(event):
    """
    å˜—è©¦ä½¿ç”¨ push_message ç™¼é€ã€Œå¾ˆæŠ±æ­‰ï¼Œä½¿ç”¨å·²é”ä¸Šé™ã€è¨Šæ¯ï¼Œ
    ä¸¦æ¡ç”¨æŒ‡æ•¸é€€é¿æ©Ÿåˆ¶é‡è©¦è‹¥é‡åˆ° 429 éŒ¯èª¤ã€‚
    """
    target_id = event.source.group_id if event.source.type == "group" else event.source.user_id
    limit_msg = TextMessage(text="å¾ˆæŠ±æ­‰ï¼Œä½¿ç”¨å·²é”ä¸Šé™")
    push_req = PushMessageRequest(
        to=target_id,
        messages=[limit_msg]
    )
    retries = 3
    backoff_factor = 1.0
    for i in range(retries):
        try:
            messaging_api.push_message(push_req)
            print("æˆåŠŸç™¼é€ä½¿ç”¨å·²é”ä¸Šé™è¨Šæ¯çµ¦ä½¿ç”¨è€…")
            return
        except Exception as err:
            err_str = str(err)
            if "429" in err_str or "monthly limit" in err_str:
                wait_time = backoff_factor * (2 ** i)
                print(f"push_message ç™¼é€å¤±æ•— (429)ï¼Œ{wait_time} ç§’å¾Œé‡è©¦...")
                time.sleep(wait_time)
            else:
                print(f"push_message ç™¼é€å¤±æ•—: {err}")
                break
    print("æœ€çµ‚ç„¡æ³•ç™¼é€ä½¿ç”¨å·²é”ä¸Šé™è¨Šæ¯çµ¦ä½¿ç”¨è€…")

# ----------------------------------
# Main Function
# ----------------------------------
# Response Function - Sort by event "reply_message" or "push_message"
def send_response(event, reply_request):
    """
    ç™¼é€å›è¦†è¨Šæ¯ï¼šå¦‚æœç™¼é€å¤±æ•—ä¸”æ•æ‰åˆ° 429ï¼ˆè¶…éä½¿ç”¨é‡é™åˆ¶ï¼‰ï¼Œ
    å˜—è©¦æ”¹ç”¨ send_limit_message() ä¾†å‘ŠçŸ¥ä½¿ç”¨è€…ã€‚
    """
    try:
        if getattr(event, "_is_audio", False):
            to = event.source.group_id if event.source.type == "group" else event.source.user_id
            push_req = PushMessageRequest(
                to=to,
                messages=reply_request.messages
            )
            messaging_api.push_message(push_req)
        else:
            messaging_api.reply_message(reply_request)
    except Exception as e:
        err_str = str(e)
        if "429" in err_str or "monthly limit" in err_str:
            print("âŒ æ•æ‰åˆ° 429 éŒ¯èª¤ï¼Œè¡¨ç¤ºä½¿ç”¨å·²é”ä¸Šé™")
            send_limit_message(event)
        else:
            print(f"âŒ LINE Reply Error: {e}")

# TextMessage Handler
@handler.add(MessageEvent)  # é è¨­è™•ç† MessageEvent
def handle_message(event):
    """è™•ç† LINE æ–‡å­—è¨Šæ¯ï¼Œæ ¹æ“šæŒ‡ä»¤å›è¦†æˆ–æä¾› AI æœå‹™"""
    # æª¢æŸ¥ event.message æ˜¯å¦å­˜åœ¨
    if not hasattr(event, "message"):
        return

    # åˆ¤æ–· message è³‡æ–™å‹æ…‹ï¼š
    if isinstance(event.message, dict):
        msg_type = event.message.get("type")
        msg_text = event.message.get("text", "")
    elif hasattr(event.message, "type"):
        msg_type = event.message.type
        msg_text = getattr(event.message, "text", "")
    else:
        return
    
    # è‹¥äº‹ä»¶å·²ç¶“è¢«è™•ç†éï¼Œå‰‡ç›´æ¥è¿”å›
    if getattr(event, "_processed", False):
        return

    # å¦‚æœæ˜¯å¾èªéŸ³è½‰éŒ„è€Œä¾†çš„äº‹ä»¶ï¼Œä¹Ÿå¯ä»¥æ¨™è¨˜ç‚ºå·²è™•ç†
    if getattr(event, "_is_audio", False):
        event._processed = True

    if msg_type != "text":
        return

    # å–å¾—ä½¿ç”¨è€…èˆ‡ç¾¤çµ„è³‡è¨Šï¼ˆæ¡ç”¨ snake_caseï¼‰
    user_message = msg_text.strip().lower()
    user_id = event.source.user_id
    group_id = event.source.group_id if event.source.type == "group" else None

    # æª¢æŸ¥ç›®å‰é¸ç”¨çš„ AI æ¨¡å‹
    if group_id and group_id in user_ai_choice:
        ai_model = user_ai_choice[group_id]
    else:
        ai_model = user_ai_choice.get(user_id, "deepseek-r1-distill-llama-70b")

    print(f"ğŸ“¢ [DEBUG] {user_id if not group_id else group_id} ç•¶å‰æ¨¡å‹: {ai_model}")

    # # å…ˆæª¢æŸ¥æ˜¯å¦æœ‰"åœæ­¢ç¿»è­¯"æŒ‡ä»¤
    # if "åœ" in user_message and "ç¿»è­¯" in user_message:
    #     if user_id in user_translation_config:
    #         user_translation_config[user_id]["enabled"] = False
    #     else:
    #         user_translation_config[user_id] = {"enabled": False, "method": "", "src": "", "tgt": ""}
    #     reply_request = ReplyMessageRequest(
    #         replyToken=event.reply_token,
    #         messages=[TextMessage(text="ç¿»è­¯åŠŸèƒ½å·²åœæ­¢ã€‚")]
    #     )
    #     messaging_api.reply_message(reply_request)
    #     return

    # (1) ã€Œçµ¦æˆ‘idã€ï¼šè‹¥è¨Šæ¯ä¸­åŒæ™‚åŒ…å«ã€Œçµ¦æˆ‘ã€å’Œã€Œidã€
    if "çµ¦æˆ‘" in user_message and "id" in user_message:
        reply_text = f"æ‚¨çš„ User ID æ˜¯ï¼š\n{user_id}"
        if group_id:
            reply_text += f"\né€™å€‹ç¾¤çµ„çš„ ID æ˜¯ï¼š\n{group_id}"
        reply_request = ReplyMessageRequest(
            replyToken=event.reply_token,
            messages=[TextMessage(text=reply_text)]
        )
        send_response(event, reply_request)
        return

    # (2) ã€Œç¾¤çµ„idã€ï¼šåœ¨ç¾¤çµ„ä¸­ï¼Œè‹¥è¨Šæ¯ä¸­åŒæ™‚åŒ…å«ã€Œç¾¤çµ„ã€å’Œã€Œidã€
    if group_id and "ç¾¤çµ„" in user_message and "id" in user_message:
        reply_text = f"é€™å€‹ç¾¤çµ„çš„ ID æ˜¯ï¼š\n{group_id}"
        reply_request = ReplyMessageRequest(
            replyToken=event.reply_token,
            messages=[TextMessage(text=reply_text)]
        )
        send_response(event, reply_request)
        return

    # (2-2) è‹¥ç‚ºå€‹äººè¨Šæ¯å»è¦æ±‚ç¾¤çµ„æŒ‡ä»¤ï¼Œå›è¦†éŒ¯èª¤è¨Šæ¯
    if group_id is None and "ç¾¤çµ„" in user_message and "id" in user_message:
        reply_request = ReplyMessageRequest(
            replyToken=event.reply_token,
            messages=[TextMessage(text="âŒ æ­¤æŒ‡ä»¤åƒ…é™ç¾¤çµ„ä½¿ç”¨")]
        )
        send_response(event, reply_request)
        return
    
    # (2-3) Random response from default pool
    if "ç‹—è›‹" in user_message and "æƒ…å‹’" in user_message:
        target_id = group_id if group_id is not None else user_id
        random_reply(event.reply_token, target_id, messaging_api)
        return

    # (3) ã€Œç‹—è›‹æŒ‡ä»¤ã€ï¼šåˆ—å‡ºæ‰€æœ‰æ”¯æ´æŒ‡ä»¤
    if "æŒ‡ä»¤" in user_message and "ç‹—è›‹" in user_message:
        command_list = (
            "ğŸ“ æ”¯æ´çš„æŒ‡ä»¤ï¼š\n"
            "1. æ›æ¨¡å‹: æ›´æ› AI èªè¨€æ¨¡å‹ \n\t\tï¼ˆé è¨­ç‚º Deepseek-R1ï¼‰\n"
            "2. ç‹—è›‹å‡ºå»: æ©Ÿå™¨äººé›¢é–‹ç¾¤çµ„\n"
            "3. ç•¶å‰æ¨¡å‹: æ©Ÿå™¨äººç¾æ­£ä½¿ç”¨çš„æ¨¡å‹\n"
            "4. ç‹—è›‹ç”Ÿæˆ: ç”Ÿæˆåœ–ç‰‡\n"
            "5. ç‹—è›‹æƒ…å‹’ ç‹—è›‹çš„è¶…èƒ½åŠ›"
        )
        reply_request = ReplyMessageRequest(
            replyToken=event.reply_token,
            messages=[TextMessage(text=command_list)]
        )
        send_response(event, reply_request)
        return

    # # (4) AI æœå‹™æŒ‡ä»¤ï¼šæª¢æŸ¥ä½¿ç”¨æ¬Šé™
    # if event.source.type != "group":
    #     if user_id not in ALLOWED_USERS:
    #         reply_request = ReplyMessageRequest(
    #             replyToken=event.reply_token,
    #             messages=[TextMessage(text="âŒ ä½ æ²’æœ‰æ¬Šé™ä½¿ç”¨ AI æœå‹™")]
    #         )
    #         send_response(event, reply_request)
    #         return
    # else:
    #     if group_id not in ALLOWED_GROUPS:
    #         reply_request = ReplyMessageRequest(
    #             replyToken=event.reply_token,
    #             messages=[TextMessage(text="âŒ æœ¬ç¾¤çµ„æ²’æœ‰æ¬Šé™ä½¿ç”¨ AI æœå‹™")]
    #         )
    #         send_response(event, reply_request)
    #         return
    #     if user_id not in ALLOWED_USERS and "ç‹—è›‹" in user_message:
    #         reply_request = ReplyMessageRequest(
    #             replyToken=event.reply_token,
    #             messages=[TextMessage(text="âŒ ä½ æ²’æœ‰æ¬Šé™ä½¿ç”¨ AI æœå‹™")]
    #         )
    #         send_response(event, reply_request)
    #         return
    #     # è™•ç†ã€Œç‹—è›‹å‡ºå»ã€æŒ‡ä»¤ï¼ˆåƒ…é©ç”¨æ–¼ç¾¤çµ„ï¼‰
    #     if "ç‹—è›‹" in user_message and "å‡ºå»" in user_message and group_id:
    #         try:
    #             reply_request = ReplyMessageRequest(
    #             replyToken=event.reply_token,
    #             messages=[TextMessage(text="æˆ‘ä¹Ÿä¸æƒ³ç•™, æ°")]
    #             )
    #             send_response(event, reply_request)
    #             messaging_api.leave_group(group_id)
    #             print(f"ğŸ¶ ç‹—è›‹å·²é›¢é–‹ç¾¤çµ„ {group_id}")
    #         except Exception as e:
    #             print(f"âŒ ç„¡æ³•é›¢é–‹ç¾¤çµ„: {e}")
    #         return


    # (4) AI Group Command
    if event.source.type == "group":
        # è™•ç†ã€Œç‹—è›‹å‡ºå»ã€æŒ‡ä»¤ï¼ˆåƒ…é©ç”¨æ–¼ç¾¤çµ„ï¼‰
        if "ç‹—è›‹" in user_message and "å‡ºå»" in user_message and group_id:
            try:
                reply_request = ReplyMessageRequest(
                replyToken=event.reply_token,
                messages=[TextMessage(text="æˆ‘ä¹Ÿä¸æƒ³ç•™, æ°")]
                )
                send_response(event, reply_request)
                messaging_api.leave_group(group_id)
                print(f"ğŸ¶ ç‹—è›‹å·²é›¢é–‹ç¾¤çµ„ {group_id}")
            except Exception as e:
                print(f"âŒ ç„¡æ³•é›¢é–‹ç¾¤çµ„: {e}")
            return

    # (4-a) ã€Œç‹—è›‹ç”Ÿæˆã€æŒ‡ä»¤ï¼ˆä¾‹å¦‚åœ–ç‰‡ç”Ÿæˆï¼‰
    if "ç‹—è›‹ç”Ÿæˆ" in user_message:
        prompt = user_message.split("ç‹—è›‹ç”Ÿæˆ", 1)[1].strip()
        if not prompt:
            prompt = "ä¸€å€‹ç¾éº—çš„é¢¨æ™¯"
        print(f"ğŸ“¢ [DEBUG] åœ–ç‰‡ç”Ÿæˆ prompt: {prompt}")
        # ç›´æ¥å‚³å…¥ event.reply_tokenï¼Œè€Œä¸æ˜¯ user id
        handle_generate_image_command(event.reply_token, prompt, messaging_api)
        return


    # (4-b) ã€Œç•¶å‰æ¨¡å‹ã€æŒ‡ä»¤
    if "æ¨¡å‹" in user_message and "ç•¶å‰" in user_message:
        if group_id and group_id in user_ai_choice:
            model = user_ai_choice[group_id]
        else:
            model = user_ai_choice.get(user_id, "Deepseek-R1")
        reply_text = f"ğŸ¤– ç¾åœ¨ä½¿ç”¨çš„ AI æ¨¡å‹æ˜¯ï¼š\n{model}"
        reply_request = ReplyMessageRequest(
            replyToken=event.reply_token,
            messages=[TextMessage(text=reply_text)]
        )
        send_response(event, reply_request)
        return

    # (4-c) ã€Œæ›æ¨¡å‹ã€
    if "æ›" in user_message and "æ¨¡å‹" in user_message:
        # è‹¥æ­¤äº‹ä»¶ä¾†è‡ªèªéŸ³ï¼Œå‰‡æ”¹ç”¨ push_message
        if getattr(event, "_is_audio", False):
            target = event.source.group_id if event.source.type == "group" else event.source.user_id
            send_ai_selection_menu(event.reply_token, target, use_push=True)
        else:
            send_ai_selection_menu(event.reply_token)
        return
    
    # # (4-d) ã€ŒTranslateã€
    # if "æˆ‘è¦" in user_message and "ç¿»è­¯" in user_message:
    #     send_translation_menu(event.reply_token)
    #     send_source_language_menu(event.reply_token)
    #     send_target_language_menu(event.reply_token)
    #     return
    # # å¦‚æœä½¿ç”¨è€…è¼¸å…¥æ ¼å¼ "ç¿»è­¯èªè¨€: zh->en"ï¼Œå‰‡è§£æä¸¦å„²å­˜è¨­å®šï¼Œå•Ÿç”¨ç¿»è­¯
    # if user_message.startswith("ç¿»è­¯èªè¨€:"):
    #     try:
    #         # æ ¼å¼å‡è¨­ç‚º "ç¿»è­¯èªè¨€: æº->ç›®æ¨™"ï¼ˆä¾‹å¦‚ "ç¿»è­¯èªè¨€: zh->en"ï¼‰
    #         lang_setting = user_message.split(":", 1)[1].strip()
    #         src, tgt = lang_setting.split("->")
    #         src = src.strip()
    #         tgt = tgt.strip()
    #         if user_id not in user_translation_config:
    #             user_translation_config[user_id] = {}
    #         user_translation_config[user_id].update({"enabled": True, "source": src, "target": tgt})
    #         reply_text = f"ç¿»è­¯è¨­å®šå·²æ›´æ–°ï¼š{src} -> {tgt}"
    #     except Exception as e:
    #         reply_text = "ç¿»è­¯è¨­å®šæ ¼å¼éŒ¯èª¤ï¼Œè«‹ä½¿ç”¨æ ¼å¼ï¼šç¿»è­¯èªè¨€: zh->en"
    #     reply_request = ReplyMessageRequest(
    #         replyToken=event.reply_token,
    #         messages=[TextMessage(text=reply_text)]
    #     )
    #     messaging_api.reply_message(reply_request)
    #     return
    
    # # æª¢æŸ¥æ˜¯å¦å•Ÿç”¨äº†ç¿»è­¯è¨­å®šï¼Œè‹¥æœ‰å‰‡åªé€²è¡Œç¿»è­¯ä¸¦å›è¦†ç¿»è­¯çµæœï¼Œä¸åŸ·è¡Œ AI å›è¦†
    # if user_id in user_translation_config and user_translation_config[user_id].get("enabled"):
    #     config = user_translation_config[user_id]
    #     src_lang = config.get("src", "auto")  # è‹¥æœªè¨­å®šï¼Œå¯è¨­ç‚º "auto"
    #     tgt_lang = config.get("tgt", "en")    # é è¨­ç¿»è­¯æˆè‹±æ–‡
    #     # å°è£ç¿»è­¯éœ€æ±‚ï¼Œé€™è£¡æ¡ç”¨ ask_groq çš„æ ¼å¼ï¼Œmodel å‚³å…¥ "gpt-translation" è®“å…¶ä½¿ç”¨ç¿»è­¯å°ˆç”¨åˆ†æ”¯
    #     prompt = f"è«‹å°‡ä¸‹åˆ—æ–‡å­—å¾ {src_lang} ç¿»è­¯æˆ {tgt_lang}ï¼š\n{user_message}"
    #     translation = ask_groq(prompt, "gpt-translation")
    #     if translation:
    #         print(f"ğŸ“¢ [DEBUG] ç¿»è­¯çµæœï¼š{translation}")
    #         reply_request = ReplyMessageRequest(
    #             replyToken=event.reply_token,
    #             messages=[TextMessage(text=f"ç¿»è­¯çµæœï¼š{translation}")]
    #         )
    #         # å¦‚æœ reply token ç‚º "DUMMY"ï¼Œä»£è¡¨æ­¤äº‹ä»¶ä¾†è‡ªèªéŸ³è½‰éŒ„æµç¨‹ï¼Œéœ€ç”¨ push_message ç™¼é€
    #         if event.reply_token == "DUMMY":
    #             target_id = event.source.group_id if event.source.type == "group" else event.source.user_id
    #             push_request = PushMessageRequest(
    #                 to=target_id,
    #                 messages=reply_request.messages
    #             )
    #             messaging_api.push_message(push_request)
    #         else:
    #             messaging_api.reply_message(reply_request)
    #         return
    #     else:
    #         reply_request = ReplyMessageRequest(
    #             replyToken=event.reply_token,
    #             messages=[TextMessage(text="âŒ ç¿»è­¯å¤±æ•—ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚")]
    #         )
    #         if event.reply_token == "DUMMY":
    #             target_id = event.source.group_id if event.source.type == "group" else event.source.user_id
    #             push_request = PushMessageRequest(
    #                 to=target_id,
    #                 messages=reply_request.messages
    #             )
    #             messaging_api.push_message(push_request)
    #         else:
    #             messaging_api.reply_message(reply_request)
    #         return

    # (4-e)ã€Œç‹—è›‹æœå°‹ã€æŒ‡ä»¤ï¼šæœå°‹ + AI ç¸½çµ
    if user_message.startswith("ç‹—è›‹æœå°‹"):
        search_query = user_message.replace("ç‹—è›‹æœå°‹", "").strip()
        
        if not search_query:
            reply_text = "è«‹è¼¸å…¥è¦æœå°‹çš„å…§å®¹ï¼Œä¾‹å¦‚ï¼šç‹—è›‹æœå°‹ OpenAI"
        else:
            print(f"ğŸ“¢ [DEBUG] é€²è¡Œ Google æœå°‹: {search_query}")
            search_results = google_search(search_query)

            if not search_results:
                reply_text = "âŒ æ‰¾ä¸åˆ°ç›¸é—œè³‡æ–™ã€‚"
            else:
                reply_text = summarize_with_openai(search_results, search_query)

        reply_request = ReplyMessageRequest(
            replyToken=event.reply_token,
            messages=[TextMessage(text=reply_text)]
        )
        send_response(event, reply_request)
        return

    # (5) è‹¥åœ¨ç¾¤çµ„ä¸­ä¸”è¨Šæ¯ä¸­ä¸åŒ…å«ã€Œç‹—è›‹ã€ï¼Œå‰‡ä¸è§¸ç™¼ AI å›æ‡‰
    if event.source.type == "group" and "ç‹—è›‹" not in user_message:
        return

    # (6) é è¨­ï¼šå‘¼å« AI å›æ‡‰å‡½å¼
    if event.source.type == "group":
        if group_id and group_id in user_ai_choice:
            ai_model = user_ai_choice[group_id]
        else:
            ai_model = "deepseek-r1-distill-llama-70b"
    else:
        ai_model = user_ai_choice.get(user_id, "deepseek-r1-distill-llama-70b")
    
    gpt_reply = ask_groq(user_message, ai_model)
    try:
        reply_request = ReplyMessageRequest(
            replyToken=event.reply_token,
            messages=[TextMessage(text=gpt_reply)]
        )
        send_response(event, reply_request)
    except Exception as e:
        print(f"âŒ LINE Reply Error: {e}")

# AudioMessage Handler
@handler.add(MessageEvent, message=AudioMessageContent)
def handle_audio_message(event):
    user_id = event.source.user_id
    group_id = event.source.group_id if event.source.type == "group" else None
    reply_token = event.reply_token
    audio_id = event.message.id

    print(f"ğŸ“¢ [DEBUG] æ”¶åˆ°èªéŸ³è¨Šæ¯, ID: {audio_id}")
    audio_url = f"https://api-data.line.me/v2/bot/message/{audio_id}/content"
    headers = {"Authorization": f"Bearer {LINE_CHANNEL_ACCESS_TOKEN}"}

    try:
        # ä¸‹è¼‰èªéŸ³æª”æ¡ˆ
        response = requests.get(audio_url, headers=headers, stream=True)
        if response.status_code == 200:
            audio_path = f"/tmp/{audio_id}.m4a"
            with open(audio_path, "wb") as f:
                for chunk in response.iter_content(chunk_size=1024):
                    f.write(chunk)
            print(f"ğŸ“¢ [DEBUG] èªéŸ³æª”æ¡ˆå·²å„²å­˜: {audio_path}")

            # å‘¼å«è½‰éŒ„åŠå¾ŒçºŒå›è¦†ï¼ˆåŒæ­¥å®Œæˆï¼‰
            transcribed_text, ai_response = transcribe_and_respond_with_gpt(audio_path)
            if not transcribed_text:
                # å¦‚æœè½‰éŒ„å¤±æ•—ï¼Œç«‹å³å›è¦†å¤±æ•—è¨Šæ¯
                reply_request = ReplyMessageRequest(
                    replyToken=reply_token,
                    messages=[TextMessage(text="âŒ èªéŸ³è¾¨è­˜å¤±æ•—ï¼Œè«‹å†è©¦ä¸€æ¬¡ï¼")]
                )
                messaging_api.reply_message(reply_request)
                return

            print(f"ğŸ“¢ [DEBUG] Whisper è½‰éŒ„çµæœ: {transcribed_text}")

            # æº–å‚™å›è¦†è¨Šæ¯åˆ—è¡¨ï¼ˆå…¨éƒ¨ç”¨ reply_message ä¸€æ¬¡æ€§å›è¦†ï¼‰
            messages = []

            # å›è¦†è½‰éŒ„å…§å®¹
            messages.append(TextMessage(text=f"ğŸ™ï¸ è½‰éŒ„å…§å®¹ï¼š{transcribed_text}"))

            # æª¢æŸ¥æ˜¯å¦æœ‰ç‰¹æ®ŠæŒ‡ä»¤
            if "ç‹—è›‹ç”Ÿæˆ" in transcribed_text:
                prompt = transcribed_text.split("ç‹—è›‹ç”Ÿæˆ", 1)[1].strip()
                if not prompt:
                    prompt = "ä¸€éš»å¯æ„›çš„å°ç‹—"
                print(f"ğŸ“¢ [DEBUG] åœ–ç‰‡ç”Ÿæˆ prompt: {prompt}")
                # å‚³å…¥ reply_token è€Œé target_id
                handle_generate_image_command(event.reply_token, prompt, messaging_api)
                return


            if "ç‹—è›‹" in transcribed_text and "æƒ…å‹’" in transcribed_text:
                # å¦‚æœåŒ…å«ã€Œç‹—è›‹æƒ…å‹’ã€æŒ‡ä»¤ï¼Œå›è¦†éš¨æ©Ÿè¨Šæ¯ï¼ˆæ¨¡æ“¬å›è¦†ï¼‰
                random_msg = random.choice([
                    "ğŸ¥±ä½ çœ‹æˆ‘æœ‰æƒ³å‘Šè¨´ä½ å—ï¼Ÿ",
                    "ğŸ˜æˆ‘çŸ¥é“ä½ åœ¨æƒ³ä»€éº¼ï¼",
                    "ğŸ¤”ä½ ç¢ºå®šå—ï¼Ÿ",
                    "ğŸ˜å¥½å•¦ï¼Œä¸ç†ä½ äº†ï¼"
                ])
                messages.append(TextMessage(text=random_msg))
            elif event.source.type == "group" and "ç‹—è›‹" not in transcribed_text:
                print("ç¾¤çµ„èªéŸ³è¨Šæ¯æœªæ˜ç¢ºå‘¼å–š 'ç‹—è›‹'ï¼Œä¸é€²è¡Œaiå›è¦†ã€‚")
                reply_request = ReplyMessageRequest(
                    replyToken=reply_token,
                    messages=messages
                )
                messaging_api.reply_message(reply_request)
                return
            else:
                # é è¨­æƒ…æ³ä¸‹å›è¦† AI å›æ‡‰
                messages.append(TextMessage(text=ai_response))

            # ä½¿ç”¨ reply_message ä¸€æ¬¡æ€§å›è¦†æ‰€æœ‰è¨Šæ¯
            reply_request = ReplyMessageRequest(
                replyToken=reply_token,
                messages=messages
            )
            messaging_api.reply_message(reply_request)
        else:
            print(f"âŒ [ERROR] ç„¡æ³•ä¸‹è¼‰èªéŸ³è¨Šæ¯, API ç‹€æ…‹ç¢¼: {response.status_code}")
            reply_request = ReplyMessageRequest(
                replyToken=reply_token,
                messages=[TextMessage(text="âŒ ä¸‹è¼‰èªéŸ³æª”æ¡ˆå¤±æ•—")]
            )
            messaging_api.reply_message(reply_request)
    except Exception as e:
        print(f"âŒ [ERROR] è™•ç†èªéŸ³æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        reply_request = ReplyMessageRequest(
            replyToken=reply_token,
            messages=[TextMessage(text="âŒ èªéŸ³è™•ç†ç™¼ç”ŸéŒ¯èª¤ï¼Œè«‹ç¨å¾Œå†è©¦ï¼")]
        )
        messaging_api.reply_message(reply_request)

# Transcribe Function
def transcribe_and_respond_with_gpt(audio_path):
    """ä½¿ç”¨ GPT-4o Mini é€²è¡ŒèªéŸ³è½‰æ–‡å­—ä¸¦ç”Ÿæˆå›æ‡‰"""
    headers = {"Authorization": f"Bearer {OPENAI_API_KEY}"}
    with open(audio_path, "rb") as audio_file:
        files = {
            "file": (audio_path, audio_file, "audio/m4a"),
            "model": (None, "whisper-1"),
            "language": (None, "zh")
        }
        try:
            response = requests.post(
                "https://api.openai.com/v1/audio/transcriptions",
                headers=headers,
                files=files
            )
            if response.status_code == 200:
                result = response.json()
                transcribed_text = result.get("text", "").strip()
                print(f"ğŸ“¢ [DEBUG] Whisper è½‰éŒ„çµæœ: {transcribed_text}")
                if not transcribed_text:
                    return None, "âŒ èªéŸ³å…§å®¹éçŸ­ï¼Œç„¡æ³•è¾¨è­˜"

                # ç›´æ¥ä½¿ç”¨ openai.ChatCompletion.create() ä¾†å‘¼å« API
                completion = openai.ChatCompletion.create(
                    model="gpt-4o",  # æ­¤è™•è«‹ç¢ºèªæ‚¨æœ‰æ¬Šé™ä½¿ç”¨è©²æ¨¡å‹ï¼Œè‹¥æœ‰éœ€è¦å¯æ”¹ç‚ºå…¶ä»–æ¨¡å‹ï¼ˆä¾‹å¦‚ "gpt-3.5-turbo"ï¼‰
                    messages=[
                        {"role": "system", "content": "ä½ æ˜¯ä¸€å€‹åå«ç‹—è›‹çš„æ™ºèƒ½åŠ©æ‰‹ï¼Œè«‹ä½¿ç”¨ç¹é«”ä¸­æ–‡å›ç­”ã€‚"},
                        {"role": "user", "content": transcribed_text}
                    ]
                )
                ai_response = completion.choices[0].message.content.strip()
                return transcribed_text, ai_response
            else:
                print(f"âŒ [ERROR] Whisper API å›æ‡‰éŒ¯èª¤: {response.text}")
                return None, "âŒ èªéŸ³è¾¨è­˜å¤±æ•—ï¼Œè«‹ç¨å¾Œå†è©¦"
        except Exception as e:
            print(f"âŒ [ERROR] èªéŸ³è½‰æ–‡å­— API å¤±æ•—: {e}")
            return None, "âŒ ä¼ºæœå™¨éŒ¯èª¤ï¼Œè«‹ç¨å¾Œå†è©¦"

# Post Handler
@handler.add(PostbackEvent)
def handle_postback(event):
    user_id = event.source.user_id
    group_id = event.source.group_id if event.source.type == "group" else None
    data = event.postback.data

    model_map = {
        "model_gpt4o": "GPT-4o",
        "model_gpt4o_mini": "GPT_4o_Mini",
        "model_deepseek": "deepseek-r1-distill-llama-70b",
        "model_llama3": "llama3-8b-8192",
    }
    if data in model_map:
        if group_id:
            user_ai_choice[group_id] = model_map[data]
        else:
            user_ai_choice[user_id] = model_map[data]
        print(f"ğŸ“¢ [DEBUG] {user_id if not group_id else group_id} é¸æ“‡æ¨¡å‹: {model_map[data]}")
        reply_req = ReplyMessageRequest(
            replyToken=event.reply_token,
            messages=[TextMessage(text=f"å·²é¸æ“‡èªè¨€æ¨¡å‹: {model_map[data]}ï¼\n\nğŸ”„ è¼¸å…¥ã€Œæ›æ¨¡å‹ã€å¯é‡æ–°é¸æ“‡")]
        )
        messaging_api.reply_message(reply_req)
        return

    if data in {"translate_gpt", "translate_google"}:
        if user_id not in user_translation_config:
            user_translation_config[user_id] = {"enabled": False, "method": "", "src": "", "tgt": ""}
        if data == "translate_gpt":
            user_translation_config[user_id]["method"] = "gpt"
            reply_text = "ç¿»è­¯æ¨¡å‹é¸æ“‡ï¼šGPT"
        else:
            user_translation_config[user_id]["method"] = "google"
            reply_text = "ç¿»è­¯æ¨¡å‹é¸æ“‡ï¼šGoogle"
        print(f"ğŸ“¢ [DEBUG] {user_id} é¸æ“‡ç¿»è­¯æ–¹æ¡ˆ: {user_translation_config[user_id]['method']}")
        reply_req = ReplyMessageRequest(
            replyToken=event.reply_token,
            messages=[TextMessage(text=reply_text)]
        )
        messaging_api.reply_message(reply_req)
        target = event.source.group_id if event.source.type == "group" else user_id
        send_source_language_menu("DUMMY", target=target, use_push=True)
        return

    if data.startswith("src_"):
        src_lang = data.split("_", 1)[1]
        if user_id not in user_translation_config:
            user_translation_config[user_id] = {"enabled": False, "method": "", "src": "", "tgt": ""}
        user_translation_config[user_id]["src"] = src_lang
        print(f"ğŸ“¢ [DEBUG] {user_id} é¸æ“‡ä¾†æºèªè¨€: {src_lang}")
        reply_req = ReplyMessageRequest(
            replyToken=event.reply_token,
            messages=[TextMessage(text=f"ä¾†æºèªè¨€å·²è¨­å®šç‚º {src_lang}ã€‚\nè«‹é¸æ“‡ç¿»è­¯ç›®æ¨™èªè¨€ï¼š")]
        )
        messaging_api.reply_message(reply_req)
        target = event.source.group_id if event.source.type == "group" else user_id
        send_target_language_menu("DUMMY", target=target, use_push=True)
        return

    if data.startswith("tgt_"):
        tgt_lang = data.split("_", 1)[1]
        if user_id not in user_translation_config:
            user_translation_config[user_id] = {"enabled": False, "method": "", "src": "", "tgt": ""}
        user_translation_config[user_id]["tgt"] = tgt_lang
        user_translation_config[user_id]["enabled"] = True
        print(f"ğŸ“¢ [DEBUG] {user_id} é¸æ“‡ç›®æ¨™èªè¨€: {tgt_lang}")
        reply_req = ReplyMessageRequest(
            replyToken=event.reply_token,
            messages=[TextMessage(text=f"ç¿»è­¯è¨­å®šå®Œæˆï¼š\nä¾†æºèªè¨€ {user_translation_config[user_id]['src']} -> ç›®æ¨™èªè¨€ {tgt_lang}\nè«‹è¼¸å…¥æ¬²ç¿»è­¯å…§å®¹:")]
        )
        messaging_api.reply_message(reply_req)
        return

    reply_req = ReplyMessageRequest(
        replyToken=event.reply_token,
        messages=[TextMessage(text="æœªçŸ¥é¸æ“‡ï¼Œè«‹é‡è©¦ã€‚")]
    )
    messaging_api.reply_message(reply_req)

def send_ai_selection_menu(reply_token, target=None, use_push=False):
    """ç™¼é€ AI é¸æ“‡é¸å–®"""
    flex_contents_json = {
        "type": "carousel",
        "contents": [
            {
                "type": "bubble",
                "hero": {
                    "type": "image",
                    "url": f"{BASE_URL}/static/openai.png",
                    "size": "md"
                },
                "body": {
                    "type": "box",
                    "layout": "vertical",
                    "justifyContent": "center",
                    "contents": [
                        {"type": "text", "text": "è¼•é‡å¼·å¤§-æ”¯æ´èªéŸ³è¼¸å…¥", "weight": "bold", "size": "xl", "align": "center"},
                        {"type": "button", "style": "primary", "action": {"type": "postback", "label": "GPT-4o Mini", "data": "model_gpt4o_mini"}}
                    ]
                }
            },
            {
                "type": "bubble",
                "hero": {
                    "type": "image",
                    "url": f"{BASE_URL}/static/deepseek.png",
                    "size": "md"
                },
                "body": {
                    "type": "box",
                    "layout": "vertical",
                    "justifyContent": "center",
                    "contents": [
                        {"type": "text", "text": "èªæ„æª¢ç´¢å¼·", "weight": "bold", "size": "xl", "align": "center"},
                        {"type": "button", "style": "primary", "action": {"type": "postback", "label": "Deepseek-R1", "data": "model_deepseek"}}
                    ]
                }
            },
            {
                "type": "bubble",
                "hero": {
                    "type": "image",
                    "url": f"{BASE_URL}/static/meta.jpg",
                    "size": "md"
                },
                "body": {
                    "type": "box",
                    "layout": "vertical",
                    "justifyContent": "center",
                    "contents": [
                        {"type": "text", "text": "é•·æ–‡æœ¬é©é…", "weight": "bold", "size": "xl", "align": "center"},
                        {"type": "button", "style": "primary", "action": {"type": "postback", "label": "LLama3-8b", "data": "model_llama3"}}
                    ]
                }
            },
            {
                "type": "bubble",
                "hero": {
                    "type": "image",
                    "url": f"{BASE_URL}/static/giticon.png",  
                    "size": "md",
                    "aspectRatio": "1:1",
                    "aspectMode": "fit"
                },
                "body": {
                    "type": "box",
                    "layout": "vertical",
                    "justifyContent": "center",
                    "contents": [
                        {"type": "text", "text": "é«˜ç™»åŸºåœ°", "weight": "bold", "size": "xl", "align": "center"},
                        {"type": "button", "style": "primary", "action": {"type": "uri", "label": "é–‹å•ŸåŸºåœ°", "uri": "https://gordonsay.github.io/gordonwu/personalpage/index_personal.html"}}
                    ]
                }
            }
        ]
    }

    try:
        # å°‡ flex JSON è½‰ç‚ºå­—ä¸²ï¼Œå†è§£ææˆ FlexContainer
        flex_json_str = json.dumps(flex_contents_json)
        flex_contents = FlexContainer.from_json(flex_json_str)
        flex_message = FlexMessage(
            alt_text="è«‹é¸æ“‡ AI æ¨¡å‹",
            contents=flex_contents
        )
        reply_request = ReplyMessageRequest(
            replyToken=reply_token,
            messages=[
                TextMessage(text="ä½ å¥½ï¼Œæˆ‘æ˜¯ç‹—è›‹ğŸ¶ ï¼\nè«‹é¸æ“‡ AI æ¨¡å‹å¾Œç™¼å•ã€‚"),
                flex_message
            ]
        )
        if use_push and target:
            push_request = PushMessageRequest(
                to=target,
                messages=reply_request.messages
            )
            messaging_api.push_message(push_request)
        else:
            messaging_api.reply_message(reply_request)
    except Exception as e:
        print(f"âŒ FlexMessage Error: {e}")

def send_translation_menu(reply_token, target=None, use_push=False):
    """ç™¼é€ç¿»è­¯é¸æ“‡é¸å–®ï¼Œåƒ…åœ¨è¼¸å…¥ 'æˆ‘è¦ç¿»è­¯' æ™‚å‡ºç¾"""
    flex_contents_json = {
        "type": "carousel",
        "contents": [
            {
                "type": "bubble",
                "hero": {
                    "type": "image",
                    "url": f"{BASE_URL}/static/openai.png",  
                    "size": "md"
                },
                "body": {
                    "type": "box",
                    "layout": "vertical",
                    "justifyContent": "center",
                    "contents": [
                        {"type": "text", "text": "ç²¾æº–ä½†è¼ƒç·©æ…¢", "weight": "bold", "size": "xl", "align": "center"}
                    ]
                },
                "footer": {
                    "type": "box",
                    "layout": "vertical",
                    "contents": [
                        {"type": "button", "action": {"type": "postback", "label": "é¸æ“‡æ­¤æ–¹æ¡ˆ", "data": "translate_gpt"}}
                    ]
                }
            },
            {
                "type": "bubble",
                "hero": {
                    "type": "image",
                    "url": f"{BASE_URL}/static/googletrans1.png",  # è«‹æ›¿æ›ç‚ºå¯¦éš›åœ–ç‰‡ URL
                    "size": "md"
                },
                "body": {
                    "type": "box",
                    "layout": "vertical",
                    "justifyContent": "center",
                    "contents": [
                        {"type": "text", "text": "å¿«é€Ÿç›´è¦º", "weight": "bold", "size": "xl", "align": "center"}
                    ]
                },
                "footer": {
                    "type": "box",
                    "layout": "vertical",
                    "contents": [
                        {"type": "button", "action": {"type": "postback", "label": "é¸æ“‡æ­¤æ–¹æ¡ˆ", "data": "translate_google"}}
                    ]
                }
            }
        ]
    }

    try:
        flex_json_str = json.dumps(flex_contents_json)
        flex_contents = FlexContainer.from_json(flex_json_str)
        flex_message = FlexMessage(
            alt_text="è«‹é¸æ“‡ç¿»è­¯æ–¹æ¡ˆ",
            contents=flex_contents
        )
        reply_request = ReplyMessageRequest(
            replyToken=reply_token,
            messages=[
                TextMessage(text="è«‹é¸æ“‡ç¿»è­¯æ–¹æ¡ˆï¼š"),
                flex_message
            ]
        )
        if use_push and target:
            push_request = PushMessageRequest(
                to=target,
                messages=reply_request.messages
            )
            messaging_api.push_message(push_request)
        else:
            messaging_api.reply_message(reply_request)
    except Exception as e:
        print(f"âŒ Translation FlexMessage Error: {e}")

def send_source_language_menu(reply_token, target=None, use_push=False):
    """
    ç™¼é€ç¿»è­¯ä¾†æºèªè¨€é¸å–®ï¼Œå–®ä¸€ bubble å…§åŒ…å«æ‰€æœ‰èªè¨€æŒ‰éˆ•ã€‚
    èªè¨€é¸é …ï¼š
      ç¹é«”ä¸­æ–‡ï¼šzh-TW
      ç°¡é«”ä¸­æ–‡ï¼šzh-CN
      æ—¥æ–‡ï¼šja
      è‹±æ–‡ï¼šen
      éŸ“æ–‡ï¼ško
    """
    flex_contents_json = {
        "type": "bubble",
        "body": {
            "type": "box",
            "layout": "vertical",
            "contents": [
                {
                    "type": "text",
                    "text": "è«‹é¸æ“‡ç¿»è­¯ä¾†æºèªè¨€ï¼š",
                    "weight": "bold",
                    "size": "xl",
                    "align": "center"
                },
                {
                    "type": "box",
                    "layout": "horizontal",
                    "contents": [
                        {
                            "type": "button",
                            "action": {
                                "type": "postback",
                                "label": "ç¹é«”ä¸­æ–‡",
                                "data": "src_zh-TW"
                            }
                        },
                        {
                            "type": "button",
                            "action": {
                                "type": "postback",
                                "label": "ç®€ä½“ä¸­æ–‡",
                                "data": "src_zh-CN"
                            }
                        }
                    ]
                },
                {
                    "type": "box",
                    "layout": "horizontal",
                    "contents": [
                        {
                            "type": "button",
                            "action": {
                                "type": "postback",
                                "label": "æ—¥æœ¬èª",
                                "data": "src_ja"
                            }
                        },
                        {
                            "type": "button",
                            "action": {
                                "type": "postback",
                                "label": "English",
                                "data": "src_en"
                            }
                        },
                        {
                            "type": "button",
                            "action": {
                                "type": "postback",
                                "label": "í•œêµ­ì–´",
                                "data": "src_ko"
                            }
                        }
                    ]
                }
            ]
        }
    }
    try:
        flex_json_str = json.dumps(flex_contents_json)
        flex_contents = FlexContainer.from_json(flex_json_str)
        flex_message = FlexMessage(
            alt_text="è«‹é¸æ“‡ç¿»è­¯ä¾†æºèªè¨€",
            contents=flex_contents
        )
        reply_request = ReplyMessageRequest(
            replyToken=reply_token,
            messages=[
                TextMessage(text="è«‹é¸æ“‡ç¿»è­¯ä¾†æºèªè¨€ï¼š"),
                flex_message
            ]
        )
        if use_push and target:
            push_request = PushMessageRequest(
                to=target,
                messages=reply_request.messages
            )
            messaging_api.push_message(push_request)
        else:
            messaging_api.reply_message(reply_request)
    except Exception as e:
        print(f"âŒ Source Language FlexMessage Error: {e}")

def send_target_language_menu(reply_token, target=None, use_push=False):
    """
    ç™¼é€ç¿»è­¯ç›®æ¨™èªè¨€é¸å–®ï¼Œå–®ä¸€ bubble å…§åŒ…å«æ‰€æœ‰èªè¨€æŒ‰éˆ•ã€‚
    èªè¨€é¸é …ï¼š
      ç¹é«”ä¸­æ–‡ï¼šzh-TW
      ç°¡é«”ä¸­æ–‡ï¼šzh-CN
      æ—¥æ–‡ï¼šja
      è‹±æ–‡ï¼šen
      éŸ“æ–‡ï¼ško
    """
    flex_contents_json = {
        "type": "bubble",
        "body": {
            "type": "box",
            "layout": "vertical",
            "contents": [
                {
                    "type": "text",
                    "text": "è«‹é¸æ“‡ç¿»è­¯ç›®æ¨™èªè¨€ï¼š",
                    "weight": "bold",
                    "size": "xl",
                    "align": "center"
                },
                {
                    "type": "box",
                    "layout": "horizontal",
                    "contents": [
                        {
                            "type": "button",
                            "action": {
                                "type": "postback",
                                "label": "ç¹é«”ä¸­æ–‡",
                                "data": "tgt_zh-TW"
                            }
                        },
                        {
                            "type": "button",
                            "action": {
                                "type": "postback",
                                "label": "ç®€ä½“ä¸­æ–‡",
                                "data": "tgt_zh-CN"
                            }
                        }
                    ]
                },
                {
                    "type": "box",
                    "layout": "horizontal",
                    "contents": [
                        {
                            "type": "button",
                            "action": {
                                "type": "postback",
                                "label": "æ—¥æœ¬èª",
                                "data": "tgt_ja"
                            }
                        },
                        {
                            "type": "button",
                            "action": {
                                "type": "postback",
                                "label": "English",
                                "data": "tgt_en"
                            }
                        },
                        {
                            "type": "button",
                            "action": {
                                "type": "postback",
                                "label": "í•œêµ­ì–´",
                                "data": "tgt_ko"
                            }
                        }
                    ]
                }
            ]
        }
    }
    try:
        flex_json_str = json.dumps(flex_contents_json)
        flex_contents = FlexContainer.from_json(flex_json_str)
        flex_message = FlexMessage(
            alt_text="è«‹é¸æ“‡ç¿»è­¯ç›®æ¨™èªè¨€",
            contents=flex_contents
        )
        reply_request = ReplyMessageRequest(
            replyToken=reply_token,
            messages=[
                TextMessage(text="è«‹é¸æ“‡ç¿»è­¯ç›®æ¨™èªè¨€ï¼š"),
                flex_message
            ]
        )
        if use_push and target:
            push_request = PushMessageRequest(
                to=target,
                messages=reply_request.messages
            )
            messaging_api.push_message(push_request)
        else:
            messaging_api.reply_message(reply_request)
    except Exception as e:
        print(f"âŒ Target Language FlexMessage Error: {e}")

def translate_with_gpt(text, src, tgt):
    """
    ä½¿ç”¨ OpenAI çš„ GPT-3.5-turbo é€²è¡Œç¿»è­¯ï¼Œ
    å°‡è¼¸å…¥æ–‡å­—å¾ src èªè¨€ç¿»è­¯æˆ tgt èªè¨€ã€‚

    åƒæ•¸:
      text: è¦ç¿»è­¯çš„æ–‡å­—
      src: æºèªè¨€ä»£ç¢¼ï¼ˆä¾‹å¦‚ "zh-TW" è¡¨ç¤ºç¹é«”ä¸­æ–‡ã€"zh-CN" è¡¨ç¤ºç°¡é«”ä¸­æ–‡ã€"ja" è¡¨ç¤ºæ—¥æ–‡ã€"en" è¡¨ç¤ºè‹±æ–‡ã€"ko" è¡¨ç¤ºéŸ“æ–‡ï¼‰
      tgt: ç›®æ¨™èªè¨€ä»£ç¢¼ï¼ˆä¾‹å¦‚ "en"ã€"zh-TW" ç­‰ï¼‰
    """
    prompt = f"è«‹å°‡ä¸‹åˆ—æ–‡å­—å¾ {src} ç¿»è­¯æˆ {tgt}ï¼š\n{text}"
    try:
        # æ³¨æ„ï¼šæ–°ç‰ˆ OpenAI SDK å¿…é ˆç›´æ¥ä½¿ç”¨ openai.ChatCompletion.create()
        response = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",  # ä½¿ç”¨æœ‰æ•ˆä¸”æ‚¨æœ‰æ¬Šé™ä½¿ç”¨çš„æ¨¡å‹
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„ç¿»è­¯å°ˆå®¶ï¼Œè«‹ç²¾æº–ä¸”è‡ªç„¶åœ°ç¿»è­¯ä»¥ä¸‹å…§å®¹ã€‚"},
                {"role": "user", "content": prompt}
            ]
        )
        translation = response.choices[0].message.content.strip()
        return translation
    except Exception as e:
        print(f"âŒ ç¿»è­¯éŒ¯èª¤: {e}")
        return None

def ask_groq(user_message, model):
    """
    æ ¹æ“šé¸æ“‡çš„æ¨¡å‹åŸ·è¡Œä¸åŒçš„ APIï¼š
      - å¦‚æœ model ç‚º "gpt-4o" æˆ– "gpt_4o_mini"ï¼Œå‰‡å‘¼å« OpenAI APIï¼ˆåŸæœ‰é‚è¼¯ï¼‰
      - å¦‚æœ model ç‚º "gpt-translation"ï¼Œå‰‡ä½¿ç”¨ç¿»è­¯æ¨¡å¼ï¼Œè½‰æ›ç‚ºæœ‰æ•ˆæ¨¡å‹ï¼ˆä¾‹å¦‚ "gpt-3.5-turbo"ï¼‰ä¸¦ä½¿ç”¨ç¿»è­¯ prompt
      - å¦å‰‡ä½¿ç”¨ Groq API
    """
    print(f"[ask_groq] æ¨¡å‹åƒæ•¸: {model}")
    try:
        if model.lower() in ["gpt-4o", "gpt_4o_mini"]:
            # (åŸæœ‰çš„ GPT-4o Mini é‚è¼¯)
            openai_client = openai.ChatCompletion.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "user", "content": "ä½ æ˜¯ä¸€å€‹åå«ç‹—è›‹çš„åŠ©æ‰‹ï¼Œç›¡é‡åªä½¿ç”¨ç¹é«”ä¸­æ–‡ç²¾ç°¡è·Ÿæœ‹å‹çš„èªæ°£çš„å¹½é»˜å›ç­”, ç´„è«20å­—å…§ï¼Œé™åˆ¶ä¸è¶…é50å­—ï¼Œé™¤éç•¶è«‹æ±‚ç‚ºç¿»è­¯æ™‚, å…¨éƒ¨å…§å®¹éƒ½éœ€è¦å®Œæˆç¿»è­¯ä¸æ®˜ç•™åŸèªè¨€ã€‚"},
                    {"role": "user", "content": user_message}
                ]
            )
            print(f"ğŸ“¢ [DEBUG] OpenAI API å›æ‡‰: {openai_client}")
            return openai_client.choices[0].message.content.strip()

        elif model.lower() == "gpt-translation":
            # å°æ–¼ç¿»è­¯ä»»å‹™ï¼Œä½¿ç”¨æœ‰æ•ˆçš„æ¨¡å‹ï¼ˆä¾‹å¦‚ gpt-3.5-turboï¼‰ï¼Œä¸¦ä¸å¼·åˆ¶å›è¦†ç¹é«”ä¸­æ–‡
            effective_model = "gpt-3.5-turbo"
            print(f"ğŸ“¢ [DEBUG] å‘¼å« OpenAI API (ç¿»è­¯æ¨¡å¼)ï¼Œä½¿ç”¨æ¨¡å‹: {effective_model}")
            response = openai.ChatCompletion.create(
                model=effective_model,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä½å°ˆæ¥­ç¿»è­¯å°ˆå®¶ï¼Œè«‹æ ¹æ“šä½¿ç”¨è€…çš„éœ€æ±‚ç²¾æº–ä¸”è‡ªç„¶åœ°ç¿»è­¯ä»¥ä¸‹å…§å®¹ã€‚ç•¶è«‹æ±‚ç‚ºç¿»è­¯æ™‚, å…¨éƒ¨å…§å®¹ä¸€å®šéƒ½è¦å®Œæˆç¿»è­¯ä¸æ®˜ç•™åŸèªè¨€"},
                    {"role": "user", "content": user_message}
                ]
            )
            return response.choices[0].message.content.strip()

        else:
            # Groq API é‚è¼¯ (ä¿æŒä¸è®Š)
            chat_completion = client.chat.completions.create(
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€å€‹åå«ç‹—è›‹çš„åŠ©æ‰‹ï¼Œè·Ÿä½¿ç”¨è€…æ˜¯æœ‹å‹é—œä¿‚, ç›¡é‡åªä½¿ç”¨ç¹é«”ä¸­æ–‡æ–¹å¼é€²è¡Œå¹½é»˜å›ç­”, ç´„è«20å­—å…§ï¼Œé™åˆ¶ä¸è¶…é50å­—, é™¤éç•¶è«‹æ±‚ç‚ºç¿»è­¯æ™‚, å…¨éƒ¨å…§å®¹éƒ½éœ€è¦å®Œæˆç¿»è­¯ä¸æ®˜ç•™åŸèªè¨€ã€‚"},
                    {"role": "user", "content": user_message},
                ],
                model=model.lower(),
            )
            if not chat_completion.choices:
                return "âŒ ç‹—è›‹ç„¡æ³•å›æ‡‰ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚"
            content = chat_completion.choices[0].message.content.strip()
            content = re.sub(r"<think>.*?</think>", "", content, flags=re.DOTALL).strip()
            return content

    except Exception as e:
        print(f"âŒ AI API å‘¼å«éŒ¯èª¤: {e}")
        return "âŒ ç‹—è›‹ä¼ºæœå™¨éŒ¯èª¤ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚"

def random_reply(reply_token, target, messaging_api):

    reply_messages = [
        "ğŸ¥±ä½ çœ‹æˆ‘æœ‰æƒ³å‘Šè¨´ä½ å—ï¼Ÿ",
        "ğŸ˜çœŸå‡, æ€é‚£éº¼æ£’ä½ é˜¿",
        "ğŸ¤”ä¸Šæ¬¡æˆ‘æœ‰èªªéäº†, ä¸‹æ¬¡é‚„è¦èªªå°å§",
        "ğŸ˜å¹´è¼•äººè¦å¤šå¿è€ æˆ‘ä¹Ÿæ˜¯é€™æ¨£éä¾†çš„",
        "ä½ ä»¥å‰éƒ½ä¸æœƒé€™æ¨£çš„ğŸ¤·â€â™‚ï¸",
        "æˆ‘é€™æ˜¯ç‚ºäº†ä½ å¥½ğŸ¤¥"
    ]
    chosen_message = random.choice(reply_messages)
    reply_request = ReplyMessageRequest(
        replyToken=reply_token,
        messages=[TextMessage(text=chosen_message)]
    )
    if reply_token == "DUMMY":
        push_request = PushMessageRequest(
            to=target,
            messages=[TextMessage(text=chosen_message)]
        )
        messaging_api.push_message(push_request)
    else:
        messaging_api.reply_message(reply_request)

def generate_image_with_openai(prompt):
    """
    ä½¿ç”¨ OpenAI åœ–åƒç”Ÿæˆ API ç”Ÿæˆåœ–ç‰‡ï¼Œè¿”å›åœ–ç‰‡ URLã€‚
    åƒæ•¸:
      prompt: åœ–åƒç”Ÿæˆæç¤ºæ–‡å­—
    """
    try:
        response = openai.Image.create(
            prompt=f"{prompt} è«‹æ ¹æ“šä¸Šè¿°æè¿°ç”Ÿæˆåœ–ç‰‡ã€‚å¦‚æœæè¿°æ¶‰åŠäººç‰©ï¼Œä»¥å¯æ„›å¡é€šé¢¨æ ¼å‘ˆç¾, è¦æ±‚é¢éƒ¨æ¯”ä¾‹æ­£ç¢ºï¼Œä¸å‡ºç¾æ‰­æ›²ã€ç•¸å½¢æˆ–é¡å¤–è‚¢é«”ï¼Œä¸”åœ–åƒéœ€é«˜è§£æåº¦ä¸”ç´°ç¯€è±å¯Œï¼›å¦‚æœæè¿°æ¶‰åŠäº‹ä»¶ä¸”æœªæŒ‡å®šé¢¨æ ¼ï¼Œè«‹ä»¥å¯æ„›å¡é€šé¢¨æ ¼å‘ˆç¾ï¼›å¦‚æœæè¿°æ¶‰åŠç‰©å“ï¼Œè«‹ç”Ÿæˆæ¸…æ™°ä¸”ç²¾ç¾çš„ç‰©å“åœ–åƒï¼ŒåŒæ™‚é¿å…å‡ºç¾è®“äººè¦ºå¾—å™å¿ƒæˆ–åèƒƒçš„æ•ˆæœã€‚",
            n=1,
            size="512x512"
        )
        data = response.get("data", [])
        if not data or len(data) == 0:
            print("âŒ ç”Ÿæˆåœ–ç‰‡æ™‚æ²’æœ‰å›å‚³ä»»ä½•è³‡æ–™")
            return None
        image_url = data[0].get("url")
        print(f"ç”Ÿæˆçš„åœ–ç‰‡ URLï¼š{image_url}")
        return image_url
    except Exception as e:
        print(f"âŒ ç”Ÿæˆåœ–åƒéŒ¯èª¤: {e}")
        return None

def async_generate_and_send_image(target_id, prompt, messaging_api):
    image_url = generate_image_with_openai(prompt)
    if image_url:
        push_request = PushMessageRequest(
            to=target_id,
            messages=[ImageMessage(original_content_url=image_url, preview_image_url=image_url)]
        )
        messaging_api.push_message(push_request)
    else:
        push_request = PushMessageRequest(
            to=target_id,
            messages=[TextMessage(text="âŒ åœ–ç‰‡ç”Ÿæˆå¤±æ•—ï¼Œè«‹ç¨å¾Œå†è©¦ï¼")]
        )
        messaging_api.push_message(push_request)

def handle_generate_image_command(reply_token, prompt, messaging_api):
    """
    å‘¼å«åœ–ç‰‡ç”Ÿæˆ API ä¸¦ä½¿ç”¨ reply_message ä¸€æ¬¡æ€§å›è¦†æ‰€æœ‰è¨Šæ¯ã€‚
    æ³¨æ„ï¼šæ­¤æµç¨‹å¿…é ˆåœ¨ reply token æœ‰æ•ˆæœŸé™å…§å®Œæˆï¼ˆç´„ 60 ç§’ï¼‰ã€‚
    """
    messages = []

    # åŒæ­¥å‘¼å« OpenAI åœ–åƒç”Ÿæˆ API
    image_url = generate_image_with_openai(prompt)
    if image_url:
        messages.append(ImageMessage(original_content_url=image_url, preview_image_url=image_url))
        messages.append(TextMessage(text="ç”Ÿæˆå®Œæˆ, ä½ ç§ç§ğŸ§"))
    else:
        messages.append(TextMessage(text="âŒ åœ–ç‰‡ç”Ÿæˆå¤±æ•—ï¼Œè«‹ç¨å¾Œå†è©¦ï¼"))

    # å»ºç«‹ä¸¦ç™¼é€ ReplyMessageRequestï¼ˆåªä½¿ç”¨ reply_messageï¼‰
    reply_request = ReplyMessageRequest(
        replyToken=reply_token,  # é€™è£¡ä¸€å®šè¦å‚³å…¥æ­£ç¢ºçš„ reply token
        messages=messages
    )
    try:
        messaging_api.reply_message(reply_request)
        print("æˆåŠŸä½¿ç”¨ reply_message å›è¦†åœ–ç‰‡ç”Ÿæˆçµæœ")
    except Exception as e:
        print(f"âŒ ç™¼é€åœ–ç‰‡å›è¦†æ™‚å‡ºéŒ¯: {e}")

def summarize_with_openai(search_results, query):
    """ä½¿ç”¨ OpenAI API é€²è¡Œæ‘˜è¦"""
    if not search_results:
        print("âŒ [DEBUG] æ²’æœ‰æœå°‹çµæœï¼Œç„¡æ³•æ‘˜è¦ï¼")
        return "æ‰¾ä¸åˆ°ç›¸é—œè³‡æ–™ã€‚"

    formatted_results = "\n".join(search_results)

    print(f"ğŸ“¢ [DEBUG] å‚³é€çµ¦ OpenAI çš„å…§å®¹:\n{formatted_results}")

    prompt = f"""
    ä½¿ç”¨è€…æŸ¥è©¢: {query}

    ä»¥ä¸‹æ˜¯ Google æœå°‹çµæœçš„æ¨™é¡Œèˆ‡é€£çµï¼š
    {formatted_results}

    æ ¹æ“šé€™äº›çµæœæä¾›ç°¡å–®æ˜ç­çš„æ‘˜è¦ï¼ˆ100 å­—å…§ï¼‰ã€‚
    **è«‹å¿½ç•¥æ–°èç¶²ç«™é¦–é æˆ–éæœŸæ–°èï¼ˆå¦‚ 2017 å›é¡§æ–°èï¼‰ï¼Œåƒ…ç¸½çµæœ€æ–°çš„æœ‰æ•ˆå…§å®¹**ã€‚
    **è‹¥è³‡æ–™å¤šç‚ºå¤©æ°£å…§å®¹, è«‹ç¢ºèªæ—¥æœŸç¬¦åˆå¾Œç°¡è¿°æ¨è«–å¤©æ°£å¯èƒ½æœ‰ä»€éº¼è®ŠåŒ–**ã€‚
    **è‹¥è³‡æ–™å¤šç‚ºè²¡é‡‘è‚¡å¸‚å…§å®¹, è«‹ç°¡è¿°åœ¨é€™äº›è³‡æ–™å…§å¯ä»¥çŸ¥é“ä»€éº¼è¶¨å‹¢**
    **è‹¥è³‡æ–™å¤šå¨›æ¨‚å…«å¦å…§å®¹, è«‹ç°¡è¿°åœ¨é€™äº›è³‡æ–™å…§å¯ä»¥çŒœæ¸¬æœ‰ä»€éº¼äº‹æƒ…ç™¼ç”Ÿäº†**
    """

    response = openai.ChatCompletion.create(
        model="gpt-4o-mini",
        messages=[{"role": "system", "content": "ä½ æ˜¯ä¸€å€‹æ™ºæ…§åŠ©ç†ï¼Œä¾ç…§é€™äº›è³‡æ–™, æ¢åˆ—ç¸½çµè·Ÿé™„ä¸Šé€£çµã€‚"},
                  {"role": "user", "content": prompt}]
    )

    reply_text = response["choices"][0]["message"]["content"].strip()

    print(f"ğŸ“¢ [DEBUG] OpenAI å›æ‡‰: {reply_text}")

    return reply_text

def google_search(query):
    """ä½¿ç”¨ Google Custom Search API é€²è¡Œæœå°‹"""
    url = f"https://www.googleapis.com/customsearch/v1?q={query}&key={GOOGLE_SEARCH_KEY}&cx={GOOGLE_CX}"
    response = requests.get(url)

    print(f"ğŸ“¢ [DEBUG] Google æœå°‹ API å›æ‡‰: {response.status_code}")
    print(f"ğŸ“¢ [DEBUG] Google API å›æ‡‰å…§å®¹: {response.text}")

    if response.status_code != 200:
        return None

    results = response.json()
    search_results = []
    
    if "items" in results:
        for item in results["items"][:5]:  # å–å‰ 5 ç­†æœå°‹çµæœ
            search_results.append(f"{item['title']} - {item['link']}")

    print(f"ğŸ“¢ [DEBUG] Google æœå°‹çµæœ: {search_results}")

    return search_results if search_results else None

if __name__ == "__main__":
    port = int(os.environ.get("PORT", 5000))  # ä½¿ç”¨ Render æä¾›çš„ PORT
    app.run(host="0.0.0.0", port=port, debug=False)  # ç§»é™¤ debug=True
